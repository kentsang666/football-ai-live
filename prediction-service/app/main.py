"""
è¶³çƒæ¯”èµ›é¢„æµ‹æœåŠ¡ - äº‘ç«¯éƒ¨ç½²ç‰ˆæœ¬
æ”¯æŒ Railway / Heroku / Docker ç­‰å¹³å°
"""

import asyncio
import json
import os
from contextlib import asynccontextmanager
from datetime import datetime
from pathlib import Path
from typing import Optional

from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import redis.asyncio as redis
import numpy as np

# å°è¯•å¯¼å…¥ joblibï¼ˆç”¨äºåŠ è½½æ¨¡å‹ï¼‰
try:
    import joblib
    JOBLIB_AVAILABLE = True
except ImportError:
    JOBLIB_AVAILABLE = False
    print("âš ï¸ joblib æœªå®‰è£…ï¼Œå°†ä½¿ç”¨ç®€å•ç®—æ³•")

# ===========================================
# äº‘ç«¯éƒ¨ç½²é…ç½®
# ===========================================

# ç«¯å£ï¼šä¼˜å…ˆä½¿ç”¨ç¯å¢ƒå˜é‡ PORT
PORT = int(os.getenv("PORT", "8000"))

# Redis URLï¼šæ”¯æŒå¤šç§ç¯å¢ƒå˜é‡å
REDIS_URL = (
    os.getenv("REDIS_URL") or 
    os.getenv("REDIS_PRIVATE_URL") or 
    os.getenv("REDISCLOUD_URL") or 
    "redis://localhost:6379"
)

# æ•°æ®åº“ URL
DATABASE_URL = (
    os.getenv("DATABASE_URL") or 
    os.getenv("DATABASE_PRIVATE_URL") or 
    "postgresql://football_user:football_pass@localhost:5432/football_db"
)

# å‰ç«¯ URLï¼ˆç”¨äº CORSï¼‰
FRONTEND_URL = os.getenv("FRONTEND_URL", "http://localhost:5173")

# æ¨¡å‹è·¯å¾„
MODEL_PATH = Path(__file__).parent.parent / "ml" / "model_v1.pkl"

# ç¯å¢ƒ
ENVIRONMENT = os.getenv("RAILWAY_ENVIRONMENT") or os.getenv("NODE_ENV") or "development"

# ===========================================
# å…¨å±€å˜é‡
# ===========================================

redis_client = None
ml_model = None
model_metadata = None

# æ•°æ®åº“è¿æ¥
DB_ENABLED = os.getenv("DB_ENABLED", "false").lower() == "true"
database = None

if DB_ENABLED:
    try:
        from databases import Database
        database = Database(DATABASE_URL)
    except ImportError:
        print("âš ï¸ databases åº“æœªå®‰è£…ï¼Œè·³è¿‡æ•°æ®åº“åŠŸèƒ½")
        DB_ENABLED = False


# ===========================================
# Redis è¿æ¥
# ===========================================

async def get_redis_client():
    """è·å– Redis å®¢æˆ·ç«¯ï¼Œæ”¯æŒäº‘ç«¯ TLS è¿æ¥"""
    global redis_client
    
    if redis_client is not None:
        return redis_client
    
    # è§£æ Redis URLï¼Œå¤„ç†äº‘ç«¯ TLS
    redis_kwargs = {
        "encoding": "utf-8",
        "decode_responses": True
    }
    
    # Railway Redis ä½¿ç”¨ rediss:// åè®®è¡¨ç¤º TLS
    if REDIS_URL.startswith("rediss://"):
        redis_kwargs["ssl"] = True
        redis_kwargs["ssl_cert_reqs"] = None  # è·³è¿‡è¯ä¹¦éªŒè¯ï¼ˆRailway éœ€è¦ï¼‰
    
    redis_client = redis.from_url(REDIS_URL, **redis_kwargs)
    return redis_client


# ===========================================
# æ¨¡å‹åŠ è½½
# ===========================================

def load_ml_model() -> bool:
    """åŠ è½½æœºå™¨å­¦ä¹ æ¨¡å‹"""
    global ml_model, model_metadata
    
    if not JOBLIB_AVAILABLE:
        print("âš ï¸ joblib ä¸å¯ç”¨ï¼Œè·³è¿‡æ¨¡å‹åŠ è½½")
        return False
    
    if not MODEL_PATH.exists():
        print(f"âš ï¸ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {MODEL_PATH}")
        print("   è¯·å…ˆè¿è¡Œè®­ç»ƒè„šæœ¬: python ml/train_model.py")
        return False
    
    try:
        print(f"ğŸ“‚ åŠ è½½æ¨¡å‹: {MODEL_PATH}")
        model_data = joblib.load(MODEL_PATH)
        
        ml_model = model_data['model']
        model_metadata = {
            'version': model_data.get('version', 'unknown'),
            'feature_columns': model_data.get('feature_columns', []),
            'classes': model_data.get('classes', ['home_win', 'draw', 'away_win'])
        }
        
        print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ (ç‰ˆæœ¬: {model_metadata['version']})")
        print(f"   ç‰¹å¾åˆ—: {model_metadata['feature_columns']}")
        return True
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return False


# ===========================================
# é¢„æµ‹ç®—æ³•
# ===========================================

def calculate_probabilities_ml(match_data: dict) -> dict:
    """ä½¿ç”¨æœºå™¨å­¦ä¹ æ¨¡å‹è®¡ç®—é¢„æµ‹æ¦‚ç‡"""
    global ml_model
    
    home_goals = match_data.get('home_score', 0)
    away_goals = match_data.get('away_score', 0)
    minute = match_data.get('minute', 45)
    home_shots = match_data.get('home_shots_on_target', home_goals * 3 + minute // 15)
    away_shots = match_data.get('away_shots_on_target', away_goals * 3 + minute // 15)
    red_cards = match_data.get('red_cards', 0)
    
    features = np.array([[
        home_goals, away_goals, minute,
        home_shots, away_shots, red_cards
    ]])
    
    probabilities = ml_model.predict_proba(features)[0]
    
    return {
        "home": round(float(probabilities[0]), 4),
        "draw": round(float(probabilities[1]), 4),
        "away": round(float(probabilities[2]), 4)
    }


def calculate_probabilities_simple(match_data: dict) -> dict:
    """ç®€å•ç®—æ³•ï¼ˆå›é€€æ–¹æ¡ˆï¼‰"""
    p_home, p_draw, p_away = 0.33, 0.34, 0.33
    
    home_score = match_data.get('home_score', 0)
    away_score = match_data.get('away_score', 0)
    minute = match_data.get('minute', 45)
    
    goal_diff = home_score - away_score
    
    if goal_diff > 0:
        p_home += 0.15 * min(goal_diff, 3)
        p_draw -= 0.08 * min(goal_diff, 3)
        p_away -= 0.07 * min(goal_diff, 3)
    elif goal_diff < 0:
        p_away += 0.15 * min(-goal_diff, 3)
        p_draw -= 0.08 * min(-goal_diff, 3)
        p_home -= 0.07 * min(-goal_diff, 3)
    
    time_factor = minute / 90
    if goal_diff != 0:
        leading_boost = 0.1 * time_factor
        if goal_diff > 0:
            p_home += leading_boost
            p_draw -= leading_boost * 0.5
            p_away -= leading_boost * 0.5
        else:
            p_away += leading_boost
            p_draw -= leading_boost * 0.5
            p_home -= leading_boost * 0.5
    
    total = p_home + p_draw + p_away
    return {
        "home": round(p_home / total, 4),
        "draw": round(p_draw / total, 4),
        "away": round(p_away / total, 4)
    }


def calculate_probabilities(match_data: dict) -> dict:
    """è®¡ç®—é¢„æµ‹æ¦‚ç‡ï¼ˆè‡ªåŠ¨é€‰æ‹©ç®—æ³•ï¼‰"""
    global ml_model
    
    if ml_model is not None:
        try:
            return calculate_probabilities_ml(match_data)
        except Exception as e:
            print(f"âš ï¸ ML é¢„æµ‹å¤±è´¥ï¼Œå›é€€åˆ°ç®€å•ç®—æ³•: {e}")
            return calculate_probabilities_simple(match_data)
    else:
        return calculate_probabilities_simple(match_data)


# ===========================================
# ä¸šåŠ¡é€»è¾‘
# ===========================================

async def process_match_event(event_data: dict):
    """å¤„ç†æ¯”èµ›äº‹ä»¶"""
    match_id = event_data.get('match_id')
    home_team = event_data.get('home_team', 'ä¸»é˜Ÿ')
    away_team = event_data.get('away_team', 'å®¢é˜Ÿ')
    home_score = event_data.get('home_score', 0)
    away_score = event_data.get('away_score', 0)
    minute = event_data.get('minute', 0)
    
    print(f"âš¡ [Event] {home_team} {home_score}-{away_score} {away_team} ({minute}')")

    probs = calculate_probabilities(event_data)
    algo = "ML" if ml_model is not None else "Simple"
    
    payload = {
        "match_id": match_id,
        "probabilities": probs,
        "algorithm": algo,
        "model_version": model_metadata.get('version', 'N/A') if model_metadata else 'N/A',
        "timestamp": datetime.utcnow().isoformat()
    }
    
    client = await get_redis_client()
    await client.publish("predictions", json.dumps(payload))
    print(f"ğŸš€ [å‘å¸ƒ] æ–°èµ”ç‡ ({algo}): ä¸»èƒœ {probs['home']*100:.1f}% | å¹³ {probs['draw']*100:.1f}% | å®¢èƒœ {probs['away']*100:.1f}%")

    asyncio.create_task(save_to_db(match_id, probs, event_data))


async def save_to_db(match_id: str, probs: dict, event_data: dict = None):
    """å¼‚æ­¥ä¿å­˜åˆ°æ•°æ®åº“"""
    if not DB_ENABLED or not database:
        print(f"ğŸ’¾ [DB] Saved prediction (æ¨¡æ‹Ÿæ¨¡å¼ - è·³è¿‡å®é™…å†™å…¥)")
        return
    
    query = """
        INSERT INTO predictions (match_id, home_win_prob, draw_prob, away_win_prob, model_version)
        VALUES (:match_id, :home, :draw, :away, :version)
    """
    try:
        version = model_metadata.get('version', 'v1.0') if model_metadata else 'simple'
        await database.execute(query=query, values={
            "match_id": match_id,
            "home": probs['home'],
            "draw": probs['draw'],
            "away": probs['away'],
            "version": version
        })
        print(f"ğŸ’¾ [DB] Saved prediction")
    except Exception as e:
        print(f"âŒ DB Error: {e}")


async def listen_to_match_events():
    """ç›‘å¬ Redis æ¯”èµ›äº‹ä»¶é¢‘é“"""
    try:
        client = await get_redis_client()
        pubsub = client.pubsub()
        await pubsub.subscribe("match_events")
        print("ğŸ‘‚ Python AI: Listening on channel 'match_events'...")
        
        async for message in pubsub.listen():
            if message['type'] == 'message':
                try:
                    event_data = json.loads(message['data'])
                    await process_match_event(event_data)
                except json.JSONDecodeError as e:
                    print(f"âŒ JSON è§£æé”™è¯¯: {e}")
                except Exception as e:
                    print(f"âŒ å¤„ç†äº‹ä»¶é”™è¯¯: {e}")
    except Exception as e:
        print(f"âŒ Redis ç›‘å¬é”™è¯¯: {e}")
        # é‡è¯•è¿æ¥
        await asyncio.sleep(5)
        asyncio.create_task(listen_to_match_events())


# ===========================================
# FastAPI åº”ç”¨
# ===========================================

@asynccontextmanager
async def lifespan(app: FastAPI):
    """åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç† - æœ€å°åŒ–å¯åŠ¨æ—¶é—´"""
    print("=" * 50)
    print("ğŸš€ è¶³çƒé¢„æµ‹æœåŠ¡å¯åŠ¨ä¸­...")
    print(f"ğŸ”§ ç¯å¢ƒ: {ENVIRONMENT}")
    print(f"ğŸŒ ç«¯å£: {PORT}")
    print("=" * 50)
    print("âœ… æœåŠ¡å·²å°±ç»ª - å¥åº·æ£€æŸ¥å¯ç”¨")
    
    # åå°åˆå§‹åŒ–ï¼ˆä¸é˜»å¡å¥åº·æ£€æŸ¥ï¼‰
    async def background_init():
        await asyncio.sleep(3)  # ç­‰å¾…å¥åº·æ£€æŸ¥é€šè¿‡
        
        # åŠ è½½ ML æ¨¡å‹
        model_loaded = load_ml_model()
        if model_loaded:
            print("ğŸ¤– ä½¿ç”¨æœºå™¨å­¦ä¹ æ¨¡å‹è¿›è¡Œé¢„æµ‹")
        else:
            print("ğŸ“Š ä½¿ç”¨ç®€å•ç®—æ³•è¿›è¡Œé¢„æµ‹ï¼ˆå›é€€æ¨¡å¼ï¼‰")
        
        # è¿æ¥æ•°æ®åº“
        if DB_ENABLED and database:
            try:
                await database.connect()
                print("âœ… Python AI: æ•°æ®åº“å·²è¿æ¥")
            except Exception as e:
                print(f"âš ï¸ æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
        
        # å¯åŠ¨ Redis ç›‘å¬
        print(f"ğŸ“¡ è¿æ¥ Redis: {REDIS_URL.split('@')[-1] if '@' in REDIS_URL else REDIS_URL}")
        asyncio.create_task(listen_to_match_events())
        print("=" * 50)
    
    asyncio.create_task(background_init())
    
    yield
    
    # å…³é—­æ—¶
    global redis_client
    if DB_ENABLED and database:
        await database.disconnect()
    if redis_client:
        await redis_client.close()
    print("ğŸ‘‹ æœåŠ¡å·²å…³é—­")


app = FastAPI(
    title="Football Prediction Service",
    description="å®æ—¶è¶³çƒæ¯”èµ›ç»“æœé¢„æµ‹ API - äº‘ç«¯éƒ¨ç½²ç‰ˆæœ¬",
    version="2.0.0",
    lifespan=lifespan
)

# CORS ä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        FRONTEND_URL,
        "http://localhost:5173",
        "http://localhost:3000",
        "https://*.vercel.app",
    ],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# ===========================================
# API ç«¯ç‚¹
# ===========================================

class PredictionRequest(BaseModel):
    home_score: int = 0
    away_score: int = 0
    minute: int = 45
    home_shots_on_target: Optional[int] = None
    away_shots_on_target: Optional[int] = None
    red_cards: int = 0


class PredictionResponse(BaseModel):
    home: float
    draw: float
    away: float
    algorithm: str
    model_version: str


@app.get("/")
async def root():
    """æœåŠ¡çŠ¶æ€"""
    return {
        "service": "Football Prediction Service",
        "version": "2.0.0",
        "environment": ENVIRONMENT,
        "model_loaded": ml_model is not None,
        "model_version": model_metadata.get('version') if model_metadata else None,
        "algorithm": "RandomForest" if ml_model else "Simple"
    }


@app.post("/predict", response_model=PredictionResponse)
async def predict(request: PredictionRequest):
    """æ‰‹åŠ¨é¢„æµ‹æ¥å£"""
    match_data = request.model_dump()
    probs = calculate_probabilities(match_data)
    
    return PredictionResponse(
        home=probs['home'],
        draw=probs['draw'],
        away=probs['away'],
        algorithm="ML" if ml_model else "Simple",
        model_version=model_metadata.get('version', 'N/A') if model_metadata else 'N/A'
    )


@app.get("/health")
async def health():
    """å¥åº·æ£€æŸ¥"""
    return {
        "status": "healthy",
        "environment": ENVIRONMENT,
        "model_loaded": ml_model is not None,
        "algorithm": "RandomForest" if ml_model else "Simple"
    }


@app.get("/api/v1/health")
async def health_check_v1():
    """å¥åº·æ£€æŸ¥ (v1 å…¼å®¹)"""
    return {
        "status": "healthy", 
        "service": "prediction-service", 
        "version": "v2.0",
        "model_loaded": ml_model is not None
    }


# ===========================================
# å¯åŠ¨å…¥å£ï¼ˆç”¨äºç›´æ¥è¿è¡Œï¼‰
# ===========================================

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=PORT,
        reload=ENVIRONMENT == "development"
    )
