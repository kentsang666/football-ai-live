import numpy as np
import pandas as pd
from scipy.stats import poisson
import json
import os
import time

# --- Transformer Attention Module ---
class TransformerMomentum:
    """
    è½»é‡çº§ Transformer Attention æ¨¡å‹
    ç”¨äºæ•æ‰æ¯”èµ›åŠ¨é‡çš„æ—¶é—´åºåˆ—ç‰¹å¾ (Time-Series Activity Recognition)
    
    Architecture:
    Input: Sequence of Attack Vectors [DA, SoT, Corners] (Window Size N)
    Layer: Single Head Self-Attention
    Output: Context-Aware Momentum Score (Enhanced "Sustained Pressure" metric)
    """
    def __init__(self, window_size=5):
        self.window_size = window_size
        self.history = {} # { match_id: { 'last_stats': dict, 'sequence': list_of_vectors } }
        
        # Simulated Pre-trained Weights (for Attention Query/Key/Value projection)
        # In a real scenario, these would be loaded from a .pth file
        self.W_Q = np.array([[1.2, 0.1, 0.0], [0.1, 1.0, 0.0], [0.0, 0.0, 1.0]]) # Encourage recent
        self.W_K = np.eye(3)
        self.W_V = np.eye(3)

    def softmax(self, x):
        e_x = np.exp(x - np.max(x))
        return e_x / e_x.sum(axis=0)

    def process_match(self, match_id, stats):
        """
        stats: {'home_da': 50, ...} (Cumulative)
        Returns: (home_momentum_score, away_momentum_score)
        """
        if match_id not in self.history:
            self.history[match_id] = {
                'last_stats': stats,
                'home_seq': [], # List of [DA, SoT, Corner] deltas
                'away_seq': []
            }
            return 0.0, 0.0 # No history yet

        state = self.history[match_id]
        prev = state['last_stats']
        
        # 1. Calculate Deltas (Instant Velocity)
        # Prevent negative deltas (data correction)
        h_vec = np.array([
            max(0, stats.get('home_da', 0) - prev.get('home_da', 0)),
            max(0, stats.get('home_sot', 0) - prev.get('home_sot', 0)),
            max(0, stats.get('home_corners', 0) - prev.get('home_corners', 0))
        ])
        
        a_vec = np.array([
            max(0, stats.get('away_da', 0) - prev.get('away_da', 0)),
            max(0, stats.get('away_sot', 0) - prev.get('away_sot', 0)),
            max(0, stats.get('away_corners', 0) - prev.get('away_corners', 0))
        ])
        
        # Update Last Stats
        # Only update if stats changed (to avoid duplicate zero vectors in slow polling)
        if h_vec.sum() > 0 or a_vec.sum() > 0:
            state['last_stats'] = stats
            
            # 2. Update Sequences (Sliding Window)
            state['home_seq'].append(h_vec)
            state['away_seq'].append(a_vec)
            
            if len(state['home_seq']) > self.window_size:
                state['home_seq'].pop(0)
                state['away_seq'].pop(0)
            
        # 3. Apply Attention Mechanism
        # Only run if we have enough data
        if len(state['home_seq']) < 2:
            return 0.0, 0.0
            
        h_mom = self._calculate_attention_score(np.array(state['home_seq']))
        a_mom = self._calculate_attention_score(np.array(state['away_seq']))
        
        return h_mom, a_mom

    def _calculate_attention_score(self, sequence):
        """
        sequence: (T, 3) matrix
        """
        # Simple Self-Attention
        # Q = Current (Last) State * W_Q
        # K, V = Entire Sequence * W_K, W_V
        
        current = sequence[-1] # Shape (3,)
        
        Q = np.dot(current, self.W_Q)
        K = np.dot(sequence, self.W_K.T) # (T, 3)
        V = np.dot(sequence, self.W_V.T) # (T, 3)
        
        # Attention Scores = Softmax(Q * K.T / sqrt(d))
        current_reshaped = Q.reshape(1, -1) # (1, 3)
        
        # Dot Product Similarity
        # (1, 3) dot (3, T) -> (1, T)
        attn_logits = np.dot(current_reshaped, K.T) 
        d_k = 3.0
        attn_logits = attn_logits / np.sqrt(d_k)
        
        weights = self.softmax(attn_logits.flatten()) # (T,)
        
        # Weighted Sum of Values
        # weights (T,) dot V (T, 3) -> (3,)
        context_vector = np.dot(weights, V)
        
        # Compress to scalar score (Weighted Sum of features)
        # Weights: DA=1, SoT=5, Corner=2
        feature_importance = np.array([1.0, 5.0, 2.0])
        score = np.dot(context_vector, feature_importance)
        
        return score

# --- Expected Threat (xT) Spatial Engine ---
class ExpectedThreatModel:
    """
    xT (Expected Threat) æ¨¡å‹
    åŸºäº 'éšå¼åŒºåŸŸ' (Implicit Zones) ä¼°ç®—ç»Ÿè®¡äº‹ä»¶çš„ç©ºé—´ä»·å€¼ã€‚
    
    Grid Logic (Simplified 3 Zones):
    Zone A (Build-up): Low xT (0.01) - General Play
    Zone B (Creation): Mid xT (0.05) - Dangerous Attacks
    Zone C (Finishing): High xT (0.15++ ) - Corners / SoT
    """
    def __init__(self):
        # xT Surface Values (Flattened Logic for Stats)
        self.xt_map = {
            'possession': 0.001,      # æ¯æ¬¡æ§çƒå¾®å°å¨èƒ
            'dangerous_attack': 0.06, # è¿›å…¥ Zone 14 æˆ– è¾¹è·¯æ·±å¤„
            'corner': 0.12,           # å®šä½çƒé«˜å¨èƒåŒº
            'shot_on_target': 0.35,   # æé«˜å¨èƒåŠ¨ä½œ
            'shot_off_target': 0.15   # å°„é—¨å°è¯•æœ¬èº«ä»£è¡¨å¤„äºå¥½ä½ç½®
        }
        self.history = {} # { match_id: { 'last_stats': dict } }

    def calculate_xt(self, match_id, stats):
        """
        è®¡ç®—è¿‘æœŸç”Ÿæˆçš„ç´¯è®¡ xT (Cumulative Expected Threat)
        """
        if match_id not in self.history:
            self.history[match_id] = {'last_stats': stats}
            return 0.0, 0.0 # No Delta yet

        prev = self.history[match_id]['last_stats']
        
        # Calculate Deltas (Actions happening NOW)
        h_deltas = {
            'dangerous_attack': max(0, stats.get('home_da', 0) - prev.get('home_da', 0)),
            'shot_on_target': max(0, stats.get('home_sot', 0) - prev.get('home_sot', 0)),
            'corner': max(0, stats.get('home_corners', 0) - prev.get('home_corners', 0)),
            # Not strictly tracking possession counts usually, ignore for now
        }
        
        a_deltas = {
            'dangerous_attack': max(0, stats.get('away_da', 0) - prev.get('away_da', 0)),
            'shot_on_target': max(0, stats.get('away_sot', 0) - prev.get('away_sot', 0)),
            'corner': max(0, stats.get('away_corners', 0) - prev.get('away_corners', 0)),
        }
        
        # If no new data, don't update last_stats to keep tracking delta correctly? 
        # Actually standard practice is update and return 0
        self.history[match_id]['last_stats'] = stats
        
        # Sum xT Value
        h_xt_val = sum([count * self.xt_map.get(k, 0) for k, count in h_deltas.items()])
        a_xt_val = sum([count * self.xt_map.get(k, 0) for k, count in a_deltas.items()])
        
        return h_xt_val, a_xt_val

# --- Tactical Inertia Module ---
class TacticalInertia:
    """
    æˆ˜æœ¯æƒ¯æ€§ä¿®æ­£æ¨¡å— v1.0
    å¤„ç†è¿›çƒåçš„æ¾æ‡ˆã€çº¢ç‰Œåçš„æ¿€åŠ±æ•ˆåº”ç­‰éçº¿æ€§æ—¶é—´å½±å“ã€‚
    """
    def __init__(self):
        # è®°å½•æ¯åœºæ¯”èµ›çš„å…³é”®äº‹ä»¶æ—¶é—´æˆ³ { fixture_id: { 'last_goal': ts, 'red_card': ts, 'red_card_team': 'home' } }
        self.state = {}
        
    def update_state(self, fixture_id, score_home, score_away, red_cards_home, red_cards_away):
        now = time.time()
        
        # Init
        if fixture_id not in self.state:
            self.state[fixture_id] = {
                'scores': (score_home, score_away),
                'last_goal_time': 0,
                'red_cards': (red_cards_home, red_cards_away),
                'red_card_time': 0
            }
            return

        prev = self.state[fixture_id]
        
        # Check Goal
        if (score_home + score_away) > (prev['scores'][0] + prev['scores'][1]):
            prev['last_goal_time'] = now
            prev['scores'] = (score_home, score_away)
            
        # Check Red Card
        if (red_cards_home + red_cards_away) > (prev['red_cards'][0] + prev['red_cards'][1]):
            prev['red_card_time'] = now
            prev['red_cards'] = (red_cards_home, red_cards_away)

    def get_correction_factor(self, fixture_id, team='home'):
        """
        è¿”å›ä¿®æ­£ç³»æ•° Multiplier. >1.0 è¡¨ç¤ºåŠ å¼º(æ›´æ˜“è¿›çƒ/æ›´å¼º), <1.0 è¡¨ç¤ºå‰Šå¼±.
        """
        if fixture_id not in self.state:
            return 1.0
            
        data = self.state[fixture_id]
        now = time.time()
        factor = 1.0
        
        # 1. Post-Goal Lull (è¿›çƒåçš„æ¾æ‡ˆ)
        # å‡è®¾ï¼šè¿›çƒå5åˆ†é’Ÿ(300s)å†…ï¼Œè¿›çƒæ–¹é˜²å®ˆå˜å·®(å¯¹æ–¹è¿›çƒç‡æå‡)ï¼Œè‡ªèº«è¿›æ”»å˜å·®ã€‚
        time_since_goal = now - data['last_goal_time']
        if time_since_goal < 300 and data['last_goal_time'] > 0:
            # è¿™æ˜¯ä¸€ä¸ªæ··æ²ŒæœŸï¼ŒåŒæ–¹éƒ½ä¸ç¨³å®šï¼Œé€šå¸¸æ„å‘³ç€æ³¢åŠ¨ç‡å¢åŠ 
            # è¿™é‡Œç®€å•å¤„ç†ï¼šè®© xG é¢„æµ‹ slightly damped (æ›´åŠ ä¿å®ˆ)ï¼Œå› ä¸ºæ¯”èµ›èŠ‚å¥è¢«æ‰“æ–­
            factor *= 0.9 

        # 2. Martyr Effect (å“€å…µå¿…èƒœ/çº¢ç‰Œæ¿€åŠ±)
        # å‡è®¾ï¼šçº¢ç‰Œå15åˆ†é’Ÿ(900s)å†…ï¼Œé˜²å®ˆæ–¹æ„å¿—åŠ›æå¼ºï¼Œæéš¾æ”»ç ´ã€‚
        time_since_red = now - data['red_card_time']
        if time_since_red < 900 and data['red_card_time'] > 0:
            # æ­¤æ—¶ xG äº§ç”Ÿå˜å¾—éå¸¸å›°éš¾
            factor *= 0.8
            
        return factor

# æ¨¡æ‹Ÿé…ç½®ï¼šä¸åŒäº‹ä»¶çš„æƒé‡ [1, 2]
DEFAULT_WEIGHTS = {
    'dangerous_attacks': 0.1,
    'shots_on_target': 1.0,
    'shots_off_target': 0.4,
    'corners': 0.3
}
WEIGHTS_FILE = "model_weights.json"

# --- League Volatility Constants ---
# 1.0 = Standard, >1.0 = High Scoring/Volatile, <1.0 = Defensive/Low Volatility
LEAGUE_VOLATILITY = {
    # High Volatility (å¤§çƒè”èµ›)
    "å¾·ç”²": 1.15, "å¾·å›½ç”²çº§è”èµ›": 1.15,
    "è·ç”²": 1.20, "è·å…°ç”²çº§è”èµ›": 1.20,
    "æ¾³è¶…": 1.15, "æ¾³å¤§åˆ©äºšè¶…çº§è”èµ›": 1.15,
    "æŒªè¶…": 1.12, "æŒªå¨è¶…çº§è”èµ›": 1.12,
    "ç‘å…¸è¶…": 1.10, 
    "ç¾èŒè”": 1.10, "MLS": 1.10,
    "ç‘å£«è¶…": 1.12,

    # Low Volatility (å°çƒ/é˜²å®ˆè”èµ›)
    "æ³•ä¹™": 0.85, "æ³•å›½ä¹™çº§è”èµ›": 0.85,
    "æ„ä¹™": 0.85, "æ„å¤§åˆ©ä¹™çº§è”èµ›": 0.85,
    "è¥¿ä¹™": 0.88, "è¥¿ç­ç‰™ä¹™çº§è”èµ›": 0.88,
    "é˜¿ç”²": 0.85, "é˜¿æ ¹å»·ç”²çº§è”èµ›": 0.85,
    "å¸Œè…Šè¶…": 0.82,
    "å·´ç”²": 0.90, "å·´è¥¿ç”²çº§è”èµ›": 0.90,
    "ä¿„è¶…": 0.90,
    
    # Standard/Mixed (Top 5) - Slightly Adjust
    "è‹±è¶…": 1.05, # è‹±è¶…èŠ‚å¥å¿«
    "è¥¿ç”²": 0.98, # è¥¿ç”²æ¯”è¾ƒæŠ€æœ¯æµæ§çƒ
    "æ„ç”²": 1.02, # æ„ç”²è¿‘å¹´è¿›çƒå˜å¤š
    "æ³•ç”²": 0.95,
}

# --- Star Player Constants (Demo Database) ---
# Format: "Team Name": ["Player A", "Player B"]
STAR_PLAYERS = {
    "Manchester City": ["Haaland", "De Bruyne", "Rodri"],
    "Arsenal": ["Saka", "Odegaard", "Rice"],
    "Liverpool": ["Salah", "Van Dijk", "Alisson"],
    "Bayern Munich": ["Kane", "Musiala", "Neuer"],
    "Real Madrid": ["Vinicius Jr", "Bellingham", "Mbappe"],
    "Barcelona": ["Lewandowski", "Yamal", "Pedri"],
    "PSG": ["Dembele", "Hakimi", "Marquinhos"],
    "Inter": ["Lautaro", "Barella", "Calhanoglu"],
    "Juventus": ["Vlahovic", "Bremer"],
    "AC Milan": ["Leao", "Theo Hernandez", "Pulisic"],
    "Leverkusen": ["Wirtz", "Xhaka", "Grimaldo"],
}

KEY_PLAYER_PENALTY = 0.82 # 18% reduction in xG if key players missing (heuristic)

# --- Referee Style Constants (Demo Database) ---
# strictness: Red Card probability multiplier (Affects Volatility)
# penalty: Penalty kick probability multiplier (Affects xG directly)
REFEREE_STYLES = {
    "Anthony Taylor": {"strictness": 1.1, "penalty": 1.2}, # è‹±è¶…åå“¨ï¼Œç‚¹çƒå¤š
    "Michael Oliver": {"strictness": 0.9, "penalty": 1.1}, # ç›¸å¯¹å®½æ¾
    "Mateu Lahoz": {"strictness": 1.8, "penalty": 1.4},    # è¥¿ç”²å¡ç‰Œå¤§å¸ˆ (å·²é€€å½¹ï¼Œä½œDemo)
    "Daniele Orsato": {"strictness": 1.2, "penalty": 0.9}, # æ„ç”²ä¸¥è°¨å‹
    "Szymon Marciniak": {"strictness": 1.0, "penalty": 1.3}, # ä¸–ç•Œæ¯å†³èµ›è£åˆ¤ï¼Œæ•¢å¹ç‚¹çƒ
    "Clement Turpin": {"strictness": 1.3, "penalty": 1.1}, # æ³•ç”²çº¢ç‰Œå¤š
}

# --- Fatigue & Travel Constants ---
# ç–²åŠ³ä¸»è¦å½±å“é˜²å®ˆä¸“æ³¨åº¦ï¼ˆå¯¼è‡´ä¸¢çƒå¢åŠ ï¼‰å’Œä½“èƒ½ï¼ˆè¿›æ”»æ•ˆç‡ç•¥é™ï¼‰
# è¿™é‡Œåªåš Demo ç®€åŒ–ï¼šç–²åŠ³ç³»æ•° (Fatigue Score) 0.0 ~ 1.0
# 1.0 æ»¡ç–²åŠ³ = è¿›æ”» x 0.85, é˜²å®ˆ(ç»™å¯¹æ–¹é€xG) x 1.15
FATIGUE_MAX_ATT_DROP = 0.85 
FATIGUE_MAX_DEF_LEAK = 1.15

# --- Motivation Context Constants ---
MOTIVATION_FACTORS = {
    "TITLE_RACE": 1.12,      # äº‰å†  (è¿›æ”»++ ä¸“æ³¨++)
    "RELEGATION": 1.08,      # ä¿çº§ (æ‹¼å‘½)
    "EUROPE_SPOT": 1.05,     # äº‰æ¬§æˆ˜
    "MID_TABLE": 0.90,       # ä¸­æ¸¸æ— æ¬²æ— æ±‚ (åˆ’æ°´)
    "FRIENDLY": 0.85,        # å‹è°Šèµ› (é˜²å®ˆæ¾æ‡ˆï¼Œè¿›æ”»éšç¼˜ï¼Œæ€»ä½“ç•¥é™)
    "DERBY": 1.10,           # å¾·æ¯” (è‚¾ä¸Šè…ºç´ )
}

# Simple Context Database (Demo)
# Team Name -> Context Code
TEAM_CONTEXT_DB = {
    "Manchester City": "TITLE_RACE",
    "Liverpool": "TITLE_RACE",
    "Arsenal": "TITLE_RACE",
    "Sheffield United": "RELEGATION",
    "Burnley": "RELEGATION",
    "Luton": "RELEGATION",
    "Real Madrid": "TITLE_RACE",
    "Girona": "EUROPE_SPOT",
    "Chelsea": "MID_TABLE", # ä»…ä½œç¤ºä¾‹
    "Crystal Palace": "MID_TABLE",
}

# --- Tactical Style & Clash Matrix ---
STYLE_POSSESSION = "POSSESSION"      # ä¼ æ§ (e.g. Man City)
STYLE_COUNTER = "COUNTER"            # é˜²å (e.g. Real Madrid)
STYLE_HIGH_PRESS = "HIGH_PRESS"      # é«˜å‹ (e.g. Liverpool)
STYLE_LOW_BLOCK = "LOW_BLOCK"        # ä½ä½é˜²å®ˆ/å¤§å·´
STYLE_BALANCED = "BALANCED"          # å‡è¡¡

# Demo Team Styles
TEAM_STYLE_DB = {
    "Manchester City": STYLE_POSSESSION,
    "Arsenal": STYLE_POSSESSION,
    "Barcelona": STYLE_POSSESSION,
    "Real Madrid": STYLE_COUNTER,
    "Inter": STYLE_COUNTER,
    "Atletico Madrid": STYLE_LOW_BLOCK,
    "Liverpool": STYLE_HIGH_PRESS,
    "Leverkusen": STYLE_HIGH_PRESS,
    "Burnley": STYLE_LOW_BLOCK,
}

# Matrix: (TeamA_Style, TeamB_Style) -> (TeamA_Mod, TeamB_Mod)
# Key Logic: 
# - Counter beats High Line (Possession/Press)
# - Possession struggles vs Low Block
# - Press beats Possession (Disruption)
CLASH_MATRIX = {
    (STYLE_POSSESSION, STYLE_COUNTER): (0.95, 1.15),   # ä¼ æ§è¢«é˜²åå…‹
    (STYLE_COUNTER, STYLE_POSSESSION): (1.15, 0.95),
    
    (STYLE_POSSESSION, STYLE_LOW_BLOCK): (0.88, 0.90), # æ”»åšæˆ˜ï¼Œè¿›çƒéƒ½éš¾
    (STYLE_LOW_BLOCK, STYLE_POSSESSION): (0.90, 0.88),
    
    (STYLE_HIGH_PRESS, STYLE_POSSESSION): (1.12, 0.92), # ç–¯ç‹—æµæŠ¢æ–­ä¼ æ§
    (STYLE_POSSESSION, STYLE_HIGH_PRESS): (0.92, 1.12),
    
    (STYLE_HIGH_PRESS, STYLE_LOW_BLOCK): (1.05, 0.90), # é«˜å‹èƒ½å‹æ­»å¤§å·´
    (STYLE_LOW_BLOCK, STYLE_HIGH_PRESS): (0.90, 1.05),
    
    (STYLE_COUNTER, STYLE_HIGH_PRESS): (1.10, 1.10),   # äº’çˆ†å±€ (èº«åå…¨æ˜¯ç©ºæ¡£)
    (STYLE_HIGH_PRESS, STYLE_COUNTER): (1.10, 1.10),
}

# --- Weather & Environment Constants ---
# xG Multipliers based on conditions
WEATHER_IMPACT = {
    "RAIN": 1.05,       # é›¨æˆ˜ï¼Œçƒçš®æ¹¿æ»‘ï¼Œä½çº§å¤±è¯¯å¤šï¼Œè¿œå°„æ˜“è¿› -> è¿›çƒç•¥å¤š
    "HEAVY_RAIN": 0.90, # ç§¯æ°´ä¸¥é‡ï¼Œçƒä¼ ä¸èµ·æ¥ -> è¿›çƒå°‘
    "SNOW": 0.85,       # é›ªæˆ˜ï¼Œè§†é‡å—é˜»ï¼ŒåŠ¨ä½œåƒµç¡¬ -> å°çƒ
    "HEAT": 0.92,       # é«˜æ¸©ï¼Œä½“åŠ›æ¶ˆè€—å¤§ï¼Œä¸‹åŠåœºèŠ‚å¥å´© -> è¿›çƒå°‘
    "PERFECT": 1.00     # å®Œç¾è‰çš®
}

# Hostile Environments (Mega Home Advantage)
# Multiplier for Home Team xG
FORTRESS_BONUS = {
    "Liverpool": 1.15,      # Anfield
    "Dortmund": 1.15,       # Signal Iduna Park (Yellow Wall)
    "Galatasaray": 1.20,    # Welcome to Hell
    "Boca Juniors": 1.18,   # La Bombonera
    "Napoli": 1.12,         # Maradona Stadium
    "Man Utd": 1.05,        # Old Trafford (Legacy buff decreasing...)
    "Real Madrid": 1.10,    # Bernabeu European Nights
}

class LatencyGuard:
    """
    å»¶è¿Ÿå¥—åˆ©ä¿æŠ¤ (Latency Arbitrage Protection)
    åŠŸèƒ½ï¼š
    1. ç›‘æµ‹æ•°æ®æµæ–°é²œåº¦ï¼Œè¿‡æ»¤è¿‡æœŸæ•°æ® (Stale Data)ã€‚
    2. è¿›çƒ/çº¢ç‰Œåå†»ç»“çª—å£ (Freeze Window)ï¼Œé˜²æ­¢åœ¨å¸‚åœºæœªååº”å‰è¿›è¡Œè¯¯åˆ¤ã€‚
    3. è¯†åˆ«ç›˜å£å°ç›˜çŠ¶æ€ (Market Suspension)ã€‚
    """
    def __init__(self, max_latency=30, freeze_time=60):
        self.max_latency = max_latency # ç§’
        self.freeze_time = freeze_time # è¿›çƒåå†»ç»“ç§’æ•°
        
        # State Tracking
        self.match_states = {} # { id: { 'last_score': (0,0), 'last_event_ts': 0 } }

    def check_safety(self, match_id, current_score, data_timestamp):
        """
        Check if it's safe to price this match.
        Returns: (is_safe: bool, reason: str)
        """
        now = time.time()
        
        # 1. Data Freshness Check
        # data_timestamp is Unix Epoch from API
        latency = now - data_timestamp
        if latency > self.max_latency:
            return False, f"ğŸš« æ•°æ®ä¸¥é‡å»¶è¿Ÿ ({int(latency)}s) - æ‹’ç»äº¤æ˜“"
            
        # 2. Event Freeze Check
        if match_id not in self.match_states:
            self.match_states[match_id] = {
                'last_score': current_score,
                'last_event_ts': 0
            }
            return True, "OK" # First see is safe
            
        state = self.match_states[match_id]
        
        # Detect Score Change
        if current_score != state['last_score']:
            state['last_score'] = current_score
            state['last_event_ts'] = now
            return False, "âš½ è¿›çƒå‘ç”Ÿ - å†»ç»“ä¿æŠ¤ä¸­"
            
        # Check Time since last event
        time_since = now - state['last_event_ts']
        if time_since < self.freeze_time:
            remaining = int(self.freeze_time - time_since)
            return False, f"â„ï¸ å¸‚åœºç»“ç®—å†·å´ä¸­ (ä½™ {remaining}s)"
            
        return True, "âœ… ä¿¡å·å®‰å…¨"

class KellyStaking:
    """
    å‡¯åˆ©å…¬å¼èµ„é‡‘ç®¡ç†å¼•æ“ (The Kelly Staking Engine)
    é€»è¾‘ï¼šæ ¹æ®ä¼˜åŠ¿å¤§å° (Edge) åŠ¨æ€è®¡ç®—æœ€ä½³ä¸‹æ³¨æ¯”ä¾‹ã€‚
    
    Formula: f = (bp - q) / b
    where:
        f = fraction of bankroll to bet
        b = net odds (decimal odds - 1)
        p = probability of winning (AI Model)
        q = probability of losing (1 - p)
        
    Risk Management:
    - Uses "Fractional Kelly" (default 0.25) to reduce variance.
    - Caps max stake to avoid ruin (e.g. max 5% of bankroll).
    """
    def __init__(self, fraction=0.25, max_stake=0.05):
        self.fraction = fraction
        self.max_stake = max_stake # 5% cap

    def calculate_stake(self, model_prob, market_odds):
        """
        Returns: Stake percentage (e.g. 2.5 means 2.5% of bankroll)
        """
        if market_odds <= 1.01 or model_prob <= 0:
            return 0.0
            
        b = market_odds - 1.0
        p = model_prob
        q = 1.0 - p
        
        # Standard Kelly Formula
        # f* = (p * (b + 1) - 1) / b
        # or (bp - q) / b
        
        full_kelly = (b * p - q) / b
        
        # If Edge is negative, Kelly says don't bet
        if full_kelly <= 0:
            return 0.0
            
        # Apply Fraction (Safety)
        rec_stake = full_kelly * self.fraction
        
        # Apply Cap (Risk Management)
        final_stake = min(rec_stake, self.max_stake)
        
        # Return formatted
        return round(final_stake * 100, 2) # e.g. 3.25%

class ConsensusOracle:
    """
    å¤šæºæ•°æ®å…±è¯†å¼•æ“ (Consensus Oracle / The Oracle Problem)
    
    Problem:
    API providers (even expensive ones) have glitches. A "Ghost Goal" or wrong card 
    can trigger a massive wrong bet.
    
    Solution:
    Require consensus from multiple independent feeds (Primary + Shadow).
    - If Score disagrees -> BLOCK (Critical Conflict)
    - If Time disagrees -> Use Minimum (Conservative)
    - If Stats disagree -> Average them (Noise Reduction)
    """
    def __init__(self):
        # In a real system, we might connect to:
        # 1. API-Football (Primary)
        # 2. SportMonks (Secondary)
        # 3. FlashScore Scraper (Tertiary)
        pass

    def validate(self, match_id, primary_packet, secondary_packet=None):
        """
        Verify data integrity across sources.
        Returns: (FinalDataset, TrustLevel)
        TrustLevel: 'HIGH_CONSENSUS', 'SINGLE_SOURCE', 'CONFLICT_SCORE', 'CONFLICT_RED_CARD'
        """
        # If no secondary source available, return Primary with lower trust warning
        if secondary_packet is None:
            return primary_packet, "SINGLE_SOURCE"
            
        # 1. Critical Audit: Scoreline
        p_goals = (primary_packet.get('goals', {}).get('home'), primary_packet.get('goals', {}).get('away'))
        s_goals = (secondary_packet.get('goals', {}).get('home'), secondary_packet.get('goals', {}).get('away'))
        
        # Check for None to avoid crash
        if None in p_goals: p_goals = (0,0)
        if None in s_goals: s_goals = (0,0)

        if p_goals != s_goals:
            # ä¸¥é‡å†²çªï¼šæ¯”åˆ†ä¸ä¸€è‡´ (The Oracle Problem)
            # ç­–ç•¥ï¼šç«‹å³ç†”æ–­ï¼Œç›´åˆ°äººå·¥ä»‹å…¥æˆ–æºåŒæ­¥
            return None, "CONFLICT_SCORE"
            
        # 2. Critical Audit: Red Cards (Simulated check, requires event parsing)
        # Assuming we parsed events outside, but here we do raw check if possible
        # Skip for demo simplicity, focus on Score
        
        # 3. Data Fusion: Statistics (Average to remove noise)
        # If primary says 5 shots, secondary says 7, reality is likely 6.
        # This reduces "Stat padding" or "Missed tags" errors.
        
        # We assume standard structure exists. 
        # Deep merge/average logic would go here.
        # For this demo, we trust Primary stats if Score matches.
        
        return primary_packet, "HIGH_CONSENSUS"

class MarketPsychology:
    """
    å¸‚åœºå¿ƒç†å­¦åˆ†ææ¨¡å—
    æ£€æµ‹ï¼šè¿‡åº¦ååº”ã€ææ…ŒæŠ›å”®ã€è¯±ç›˜é™·é˜±
    """
    def detect_overreaction(self, model_prob, market_odd):
        """
        Input:
            model_prob: float (0.0 - 1.0) AIæ¨¡å‹çš„èƒœç‡é¢„æµ‹
            market_odd: float (e.g. 1.95) å¸‚åœºèµ”ç‡
        Return: (Signal_Type, Confidence_Score)
        """
        if market_odd <= 1.01: return None, 0.0
        
        # Implied Probability (without margin removal for raw comparison)
        market_imp_prob = 1.0 / market_odd
        
        # 1. Panic Overreaction (ææ…Œæ€§æŠ›å”®)
        # æ¨¡å‹è®¤ä¸ºæœ‰ 60% èƒœç‡ï¼Œå¸‚åœºèµ”ç‡ 4.0 (25% æ¦‚ç‡)
        # å¸¸è§äºï¼šå¼ºé˜Ÿçº¢ç‰Œåï¼Œå¸‚åœºè¿‡åº¦çœ‹è¡°
        if model_prob - market_imp_prob > 0.25:
            return "PANIC_OVERREACTION", (model_prob - market_imp_prob)
            
        # 2. Trap / Hype (è¯±ç›˜/çƒ­åº¦è¿‡é«˜)
        # æ¨¡å‹è®¤ä¸ºåªæœ‰ 30% èƒœç‡ï¼Œå¸‚åœºèµ”ç‡ 1.3 (76% æ¦‚ç‡)
        # å¸¸è§äºï¼šç½‘çº¢çƒé˜Ÿï¼ˆå¦‚æ›¼è”/åˆ‡å°”è¥¿ï¼‰å¸ç­¹
        if market_imp_prob - model_prob > 0.30:
            return "HYPE_TRAP", (market_imp_prob - model_prob)
            
        return None, 0.0

class PressureModel:
    def __init__(self, weights=None):
        self.learning_rate = 0.01
        self.weights = DEFAULT_WEIGHTS.copy()
        
        # å°è¯•åŠ è½½å…ˆå‰çš„å­¦ä¹ æˆæœ
        self.load_weights()
        
        if weights is not None:
             self.weights.update(weights)

    def load_weights(self):
        if os.path.exists(WEIGHTS_FILE):
            try:
                with open(WEIGHTS_FILE, 'r') as f:
                    saved = json.load(f)
                    self.weights.update(saved)
            except: pass

    def save_weights(self):
        try:
            with open(WEIGHTS_FILE, 'w') as f:
                json.dump(self.weights, f, indent=4)
        except: pass

    def learn(self, result, snapshot, is_home_bet):
        """
        åœ¨çº¿å­¦ä¹ æ¥å£ (Online Learning)
        result: 1 (Win), -1 (Loss), 0 (Push)
        snapshot: æ¨èæ—¶çš„å„é¡¹æ•°æ® (Diff: Home - Away)
        is_home_bet: True if bet on Home, False if Away
        """
        if result == 0: return # èµ°æ°´ä¸å­¦ä¹ 
        
        # å®šä¹‰æ–¹å‘: å¦‚æœæ˜¯ä¸»é˜Ÿæ³¨å•ï¼Œä¸»é˜Ÿæ•°æ®è¶Šé«˜åº”è¯¥è¶Šå®¹æ˜“èµ¢ => æ­£ç›¸å…³
        # å¦‚æœæ˜¯å®¢é˜Ÿæ³¨å•ï¼Œä¸»é˜Ÿæ•°æ®è¶Šé«˜åº”è¯¥è¶Šå®¹æ˜“è¾“ => è´Ÿç›¸å…³
        # è¿™é‡Œä¸ºäº†ç®€åŒ–ï¼Œæˆ‘ä»¬åªè°ƒæ•´é€šç”¨æƒé‡ (General Weights)ï¼Œå³ "å°„æ­£" åˆ°åº•é‡ä¸é‡è¦
        
        # é€»è¾‘:
        # å¦‚æœ èµ¢äº† (result=1): 
        #   å½“æ—¶ å°„æ­£å¤š (val > 0)ï¼Œè¯´æ˜å°„æ­£ç¡®å®æœ‰ç”¨ -> å¢åŠ æƒé‡
        #   å½“æ—¶ å°„æ­£å°‘ (val < 0)ï¼Œ(è¿™ç§æƒ…å†µæ¯”è¾ƒå°‘è§ï¼Œé€šå¸¸æ˜¯ä¸»æ¨ä¸»èƒœä½†ä¸»æ•°æ®å·®ï¼Ÿ)
        
        # ç®€åŒ–ç‰ˆæ¢¯åº¦ä¸‹é™:
        # å‡è®¾ Utility = w1*da + w2*sot...
        # æˆ‘ä»¬å¸Œæœ› Utility ä¸ Result (1/-1) æ­£ç›¸å…³
        
        # å¦‚æœ bet on Home:
        #   Features = (Home_DA - Away_DA), ...
        #   Update w += alpha * result * feature
        
        # å¦‚æœ bet on Away:
        #   Features = (Away_DA - Home_DA), ...
        #   Update w += alpha * result * feature
        
        diffs = {}
        if is_home_bet:
            diffs['dangerous_attacks'] = snapshot.get('home_da', 0) - snapshot.get('away_da', 0)
            diffs['shots_on_target'] = snapshot.get('home_sot', 0) - snapshot.get('away_sot', 0)
            diffs['shots_off_target'] = 0 # æš‚ä¸å­¦ä¹ 
            diffs['corners'] = snapshot.get('home_corners', 0) - snapshot.get('away_corners', 0)
        else:
            diffs['dangerous_attacks'] = snapshot.get('away_da', 0) - snapshot.get('home_da', 0)
            diffs['shots_on_target'] = snapshot.get('away_sot', 0) - snapshot.get('home_sot', 0)
            diffs['shots_off_target'] = 0
            diffs['corners'] = snapshot.get('away_corners', 0) - snapshot.get('home_corners', 0)
            
        # å½’ä¸€åŒ– Feature (é¿å…æƒé‡çˆ†ç‚¸)ï¼Œç®€å•é™¤ä»¥ä¸€ä¸ªå¸¸æ•° (e.g. 10æ¬¡è¿›æ”»)
        for k, v in diffs.items():
            # é™åˆ¶å¹…åº¦
            val = max(min(v / 10.0, 1.0), -1.0)
            
            # æ ¸å¿ƒæ›´æ–°å…¬å¼
            if k in self.weights:
                change = self.learning_rate * result * val
                self.weights[k] += change
                # ä¿è¯æƒé‡ä¸ä¸ºè´Ÿ
                self.weights[k] = max(0.01, self.weights[k])
        
        self.save_weights()
        return self.weights

    def calculate_momentum(self, recent_stats):
        """
        è®¡ç®—è¿‡å»Nåˆ†é’Ÿçš„å‹åŠ›æŒ‡æ•°
        recent_stats: å­—å…¸ï¼ŒåŒ…å«ä¸»å®¢é˜Ÿçš„å®æ—¶æ•°æ® (flat keys: home_da, home_sot, home_corners)
        """
        # User defined logic
        home_pressure = (
            recent_stats.get('home_da', 0) * self.weights.get('dangerous_attacks', 0.1) +
            recent_stats.get('home_sot', 0) * self.weights.get('shots_on_target', 1.0) +
            recent_stats.get('home_corners', 0) * self.weights.get('corners', 0.5)
        )
        
        away_pressure = (
            recent_stats.get('away_da', 0) * self.weights.get('dangerous_attacks', 0.1) +
            recent_stats.get('away_sot', 0) * self.weights.get('shots_on_target', 1.0) +
            recent_stats.get('away_corners', 0) * self.weights.get('corners', 0.5)
        )
        
        # è¿”å›ä¸€ä¸ªè°ƒæ•´ç³»æ•°ï¼Œä¾‹å¦‚ 1.2 è¡¨ç¤ºè¿›æ”»æ•ˆç‡æå‡ 20%
        # è¿™é‡Œåšä¸€ä¸ªç®€å•çš„å½’ä¸€åŒ–å¤„ç†
        # Note: Original code handled 0 case, keeping that safe
        # home_factor = 1 + (home_pressure / 10)  # ç®€åŒ–ç®—æ³•ï¼Œå…·ä½“éœ€å›å½’æµ‹è¯•
        # away_factor = 1 + (away_pressure / 10)
        
        # To prevent division by zero or weirdness if needed, though formula is additive.
        # Returning explicit factors as per user code
        
        home_factor = 1 + (home_pressure / 10.0)
        away_factor = 1 + (away_pressure / 10.0)
        
        # EXTENSION: Returning raw pressure as well for UI display
        # Scale for UI bar (approx 0-100 range)
        # Assuming pressure around 5-10 is "high", we multiply by 10 to fill the bar
        return home_factor, away_factor, home_pressure * 10, away_pressure * 10



class LivePricing:
    """
    2. åŠ¨æ€æ³Šæ¾å®šä»· (Pricing Engine) - Replaces LiveProbability
    é€»è¾‘ï¼šç»“åˆ xGã€å‰©ä½™æ—¶é—´ã€åŠ¨é‡ç³»æ•°è®¡ç®—å®æ—¶èƒœå¹³è´Ÿæ¦‚ç‡åŠç›˜å£ã€‚
    """
    def __init__(self, pre_match_xg_home, pre_match_xg_away):
        self.base_home_xg = pre_match_xg_home
        self.base_away_xg = pre_match_xg_away

    def get_remaining_xg(self, minute, home_factor, away_factor, current_score=(0,0), league_name=None, home_missing_keys=False, away_missing_keys=False, referee_name=None, referee_stats=None, home_fatigue=0.0, away_fatigue=0.0, home_motivation_type=None, away_motivation_type=None, home_style=None, away_style=None, weather_type="PERFECT", home_team_name=None, home_transformer_mom=0.0, away_transformer_mom=0.0, home_xt=0.0, away_xt=0.0):
        """
        æ ¹æ®å‰©ä½™æ—¶é—´å’ŒåŠ¨é‡è°ƒæ•´æœŸæœ›è¿›çƒæ•° (Lambda) - å‡çº§ç‰ˆ V2.0 (å…¨å› å­é›†æˆ + æˆ˜æ„ + é£æ ¼ + å¤©æ°” + ä¸»åœºé¾™ + Transformer + xT + Referee Stats)
        """
        # User defined logic for remaining time
        time_remaining = 90 - minute
        
        # If match is over or time is negative/weird
        if time_remaining <= 0:
            return 0.0, 0.0
        
        # --- å‡çº§ 1: éçº¿æ€§æ—¶é—´è¡°å‡ (Non-Linear Time Decay) ---
        # è¶³çƒæ¯”èµ›è¿›çƒç‡å¹¶éå‡åŒ€åˆ†å¸ƒï¼Œä¸Šä¸‹åŠåœºæœ«æ®µè¿›çƒç‡é€šå¸¸æ›´é«˜
        # ç®€å•æ¨¡å‹ï¼šä½¿ç”¨å¹‚å‡½æ•°ä¿®æ­£ã€‚alpha < 1 ä¼šè®©å‰©ä½™æ¯”ä¾‹åœ¨å‰æœŸä¸‹é™æ…¢ï¼ŒåæœŸä¸‹é™å¿«ï¼ˆä¸ç¬¦åˆï¼‰ï¼Œ
        # æˆ‘ä»¬éœ€è¦çš„æ˜¯ï¼šåœ¨æ¯”èµ›æœ«æ®µï¼Œè¿›çƒå¯†åº¦åè€Œå¯èƒ½ä¸Šå‡ï¼ˆç»æ€ï¼‰ï¼Œä½†è¿™é‡Œç®—çš„æ˜¯â€œå‰©ä½™æ€»é‡â€ã€‚
        # ä¼ ç»Ÿçš„ "å‰©ä½™" æ˜¯çº¿æ€§çš„ã€‚ä½†è€ƒè™‘åˆ°ä½“åŠ›ä¸‹é™å’Œç»æ€å¿ƒæ€ï¼Œå‰©ä½™ xG åœ¨ 80åˆ†é’Ÿæ—¶å¯èƒ½æ¯” å‰©ä½™æ—¶é—´æ¯”ä¾‹ è¦é«˜ã€‚
        # è¿™é‡Œä½¿ç”¨ä¸€ä¸ªç®€å•çš„ "ç–²åŠ³/ç»æ€ç³»æ•°" (Fatigue/Desperation Factor)
        # å‡è®¾æœ€å 15 åˆ†é’Ÿè¿›çƒæ¦‚ç‡æå‡ 20%
        
        time_ratio = time_remaining / 90.0
        intensity_mult = 1.0
        
        if minute > 75: 
            intensity_mult = 1.2 # æœ«æ®µå†²åˆº
        elif minute > 40 and minute <= 45:
            intensity_mult = 1.1 # åŠåœºå‰
            
        # --- å‡çº§ 11: Transformer åŠ¨é‡ä¿®æ­£ ---
        # Transformer æ•æ‰çš„æ˜¯ "åºåˆ—ç‰¹å¾"ï¼Œæ¯”å•çº¯çš„çº¿æ€§å‹åŠ›æ›´æ•æ„Ÿäº "è¶‹åŠ¿"
        # å½’ä¸€åŒ–: å‡è®¾ score èŒƒå›´ 0-10, æˆ‘ä»¬ç»™äºˆ 0-20% çš„åŠ æˆ
        t_home_mult = 1.0 + (min(home_transformer_mom, 10.0) / 50.0) # max 20% boost
        t_away_mult = 1.0 + (min(away_transformer_mom, 10.0) / 50.0)

        # --- å‡çº§ 12 (NEW): xT (Expected Threat) Spatial Correction ---
        # xT ä»£è¡¨çš„æ˜¯ "ä½ç½®è´¨é‡" (Quality of Pitch Control)ã€‚
        # ä¸åŒäº Momentum (æ•°é‡/é¢‘ç‡)ï¼ŒxT å¥–åŠ±çš„æ˜¯ "æœ‰æ•ˆæ¨è¿›"ã€‚
        # å¦‚æœä¸€æ”¯çƒé˜Ÿ xT å¾ˆé«˜ï¼Œè¯´æ˜ä»–ä»¬ç»å¸¸æ‰“å…¥ "High Value Zones"ï¼Œè¿›çƒæ¦‚ç‡åº”æ˜¾è‘—å¢åŠ ã€‚
        # Demo Scaling: xT ç´¯ç§¯å€¼é€šå¸¸è¾ƒå° (e.g. 0.1, 0.5 per sequence). 
        # è¿™é‡Œæˆ‘ä»¬å°†æœ€è¿‘å‡ åˆ†é’Ÿäº§ç”Ÿçš„ xT ç›´æ¥è½¬åŒ–ä¸º xG çš„åŠ æˆã€‚
        
        xt_home_mult = 1.0 + (min(home_xt, 5.0) / 10.0) # å‡è®¾ xT ä¸Šé™ 5.0ï¼Œæœ€å¤§åŠ æˆ 50%
        xt_away_mult = 1.0 + (min(away_xt, 5.0) / 10.0)

        # --- å‡çº§ 2: èµ›å†µä¿®æ­£ (Game State Correction) ---
        # è½åçš„ä¸€æ–¹é€šå¸¸ä¼šæŠ•å…¥æ›´å¤šè¿›æ”»èµ„æº (Game State Effect)
        # é¢†å…ˆçš„ä¸€æ–¹é€šå¸¸ä¼šæ”¶ç¼© (Parking the Bus)
        
        gs_home_mult = 1.0
        gs_away_mult = 1.0
        
        home_goals, away_goals = current_score
        score_diff = home_goals - away_goals
        
        if minute > 60: # 60åˆ†é’Ÿåæ¯”åˆ†æ•ˆåº”é€šè¿‡
            if score_diff < 0: # ä¸»é˜Ÿè½å
                if score_diff == -1: gs_home_mult = 1.15 # è½å1çƒæœ€æ‹¼
                elif score_diff == -2: gs_home_mult = 1.10
                # é¢†å…ˆæ–¹å¯èƒ½é™ä½ xG
                gs_away_mult = 0.9 
            elif score_diff > 0: # ä¸»é˜Ÿé¢†å…ˆ
                if score_diff == 1: gs_away_mult = 1.15 # å®¢é˜Ÿæ‹¼å‘½
                elif score_diff == 2: gs_away_mult = 1.10
                gs_home_mult = 0.9 # ä¸»é˜Ÿé˜²å®ˆ
        
        # --- å‡çº§ 3: è”èµ›æ³¢åŠ¨ç‡å› å­ (League Volatility Factor) ---
        league_volatility = 1.0
        if league_name:
            # æ¨¡ç³ŠåŒ¹é…æˆ–ç›´æ¥åŒ¹é…
            for key, val in LEAGUE_VOLATILITY.items():
                if key in league_name:
                    league_volatility = val
                    break
        
        # --- å‡çº§ 5: å…³é”®çƒå‘˜ç¼ºå¸­æƒ©ç½š (Star Player Absence Penalty) ---
        star_penalty_home = KEY_PLAYER_PENALTY if home_missing_keys else 1.0
        star_penalty_away = KEY_PLAYER_PENALTY if away_missing_keys else 1.0
        
        # --- å‡çº§ 6: è£åˆ¤åè§ (Referee Bias) ---
        # Updated: accept external dynamic stats
        ref_modifier = 1.0
        if referee_stats:
             # referee_stats: {'penalty': 1.2, 'card_avg': 4.5}
             ref_modifier = referee_stats.get('penalty', 1.0)
        elif referee_name:
             # Fallback to static DB
             for r_name, traits in REFEREE_STYLES.items():
                 if r_name in referee_name:
                     ref_modifier = traits.get('penalty', 1.0)
                     break

        # --- å‡çº§ 7: ç–²åŠ³ä¸é£è¡Œè·ç¦»ä¿®æ­£ (Fatigue & Travel) ---
        # ç–²åŠ³ä¸»è¦å¯¼è‡´ï¼šè¿›æ”»æ•ˆç‡ä¸‹é™ (Att Drop) + é˜²å®ˆæ¼æ´å¢åŠ  (Def Leak)
        # è‡ªèº«è¿›çƒ lambda *= (1 - fatigue * (1 - MAX_ATT))
        # å¯¹æ–¹è¿›çƒ lambda *= (1 + fatigue * (MAX_DEF - 1))
        
        # Home Fatigue Effect
        # ä¸»é˜Ÿç–²åŠ³ -> ä¸»é˜Ÿè¿›çƒå°‘ï¼Œå®¢é˜Ÿè¿›çƒå¤š
        h_att_mod = 1.0 - (home_fatigue * (1.0 - FATIGUE_MAX_ATT_DROP))
        h_def_mod = 1.0 + (home_fatigue * (FATIGUE_MAX_DEF_LEAK - 1.0)) # è®©å®¢é˜Ÿè¿›çƒå˜å¤š
        
        # Away Fatigue Effect
        # å®¢é˜Ÿç–²åŠ³ -> å®¢é˜Ÿè¿›çƒå°‘ï¼Œä¸»é˜Ÿè¿›çƒå¤š
        a_att_mod = 1.0 - (away_fatigue * (1.0 - FATIGUE_MAX_ATT_DROP))
        a_def_mod = 1.0 + (away_fatigue * (FATIGUE_MAX_DEF_LEAK - 1.0)) # è®©ä¸»é˜Ÿè¿›çƒå˜å¤š

        # --- å‡çº§ 8: æˆ˜æ„ä¸èƒŒæ™¯ä¿®æ­£ (Motivation & Context) ---
        h_mot_mod = MOTIVATION_FACTORS.get(home_motivation_type, 1.0)
        a_mot_mod = MOTIVATION_FACTORS.get(away_motivation_type, 1.0)

        # --- å‡çº§ 9: é£æ ¼å…‹åˆ¶çŸ©é˜µ (Style Clash Matrix) ---
        # Matrix: (H_Style, A_Style) -> (H_Mod, A_Mod)
        # Default: 1.0, 1.0
        h_style_mod = 1.0
        a_style_mod = 1.0
        
        if home_style and away_style:
            # Look up clash tuple
            clash_tuple = CLASH_MATRIX.get((home_style, away_style))
            if clash_tuple:
                h_style_mod, a_style_mod = clash_tuple

        # --- å‡çº§ 10: å¤©æ°”ä¸ä¸»åœºé¾™åŠ æˆ (Weather & Fortress) ---
        weather_mod = WEATHER_IMPACT.get(weather_type, 1.0)
        
        fortress_mod = 1.0
        if home_team_name:
            # ç®€å•æ¨¡ç³ŠåŒ¹é…
            for fortress, bonus in FORTRESS_BONUS.items():
                if fortress in home_team_name:
                    fortress_mod = bonus
                    break
        
        # ç»¼åˆè®¡ç®— (Ultimate Formula)
        # Lambad Home = Base * (Time) * (Momentum) * (GameState) * (League) * (Star) * (Ref) * (Fatigue) * (Mot) * (Style) * (Weather) * (Fortress) * (Transformer) * (xT)
        live_lambda_home = self.base_home_xg * time_ratio * home_factor * intensity_mult * gs_home_mult * league_volatility * star_penalty_home * ref_modifier * h_att_mod * a_def_mod * h_mot_mod * h_style_mod * weather_mod * fortress_mod * t_home_mult * xt_home_mult
        
        live_lambda_away = self.base_away_xg * time_ratio * away_factor * intensity_mult * gs_away_mult * league_volatility * star_penalty_away * ref_modifier * a_att_mod * h_def_mod * a_mot_mod * a_style_mod * weather_mod * t_away_mult * xt_away_mult
        # å®¢é˜Ÿå½“ç„¶ä¸äº«å—é­”é¬¼ä¸»åœºåŠ æˆï¼Œç”šè‡³åº”è¯¥å—æƒ©ç½š(æš‚ä¸å‡)ï¼Œè¿™é‡ŒåªåŠ æˆä¸»é˜Ÿ
        
        return live_lambda_home, live_lambda_away
        
        # Apply Inertia factor if injected (dirty hack for demo: pass as kwargs or update globally)
        # æ›´å¥½çš„æ–¹å¼æ˜¯åœ¨ LivePricing åˆå§‹åŒ–æ—¶æŒæœ‰ inertia å®ä¾‹
        # if self.inertia:
        #     f = self.inertia.get_correction_factor(fixture_id)
        #     live_lambda_home *= f
        #     live_lambda_away *= f
        
        return live_lambda_home, live_lambda_away

    def calculate_asian_handicap_prob(self, lambda_h, lambda_a, line, current_score=(0,0)):
        """
        è®¡ç®—ç‰¹å®šç›˜å£çš„æœŸæœ›èƒœç‡ (æ”¯æŒè½¯ç›˜å£/å››åˆ†ç›˜)
        line: ç›˜å£å€¼ï¼Œä¾‹å¦‚ -0.5, -0.25, +0.25
        Return: Expected Win Probability (Weighted for Half-Win)
        """
        max_goals = 10
        cur_h, cur_a = current_score
        
        # Precompute PMFs
        h_pmf = [poisson.pmf(i, lambda_h) for i in range(max_goals)]
        a_pmf = [poisson.pmf(i, lambda_a) for i in range(max_goals)]
        
        # ç´¯åŠ ç¬¦åˆç›˜å£çš„æ¦‚ç‡
        # Win = 1.0, Half Win = 0.5, Push = 0.0, Half Loss = 0.0, Loss = 0.0 (For simple Prob)
        # But wait, purely for "Probability of winning bet", we need to define what we return.
        # Usually: Return the expected payout ratio or equivalent Win%
        # Here we return "Equivalent Win Probability" -> Full Win + 0.5 * Half Win
        
        expected_value_prob = 0.0
        
        for h in range(max_goals):
            for a in range(max_goals):
                joint_prob = h_pmf[h] * a_pmf[a]
                
                # Final score
                final_h = cur_h + h
                final_a = cur_a + a
                diff = final_h - final_a
                
                # Handicap Result Logic
                # result = diff + line
                
                # Integer Lines (0, -1, -2...)
                if line % 0.5 == 0:
                    val = diff + line
                    if val > 0: expected_value_prob += joint_prob * 1.0 # Win
                    # if val == 0: Push (0 benefit)
                    
                # Quarter Lines (-0.25, -0.75...)
                else: 
                    # Split into two bets: (line - 0.25) and (line + 0.25)
                    # e.g. -0.25 -> bets on 0 and -0.5
                    
                    # Logic 2: Direct calculation
                    # If Line = -0.25. Setup: Home vs Away.
                    # Win by 1: (-0.25 + 1) = 0.75 > 0. Win.
                    # Draw: (-0.25 + 0) = -0.25. Loss Half.
                    
                    val = diff + line
                    
                    if val >= 0.5: # Clear Win
                        expected_value_prob += joint_prob * 1.0
                    elif val <= -0.5: # Clear Loss
                        pass
                    elif abs(val) == 0.25:
                        # Case: 0.25 or -0.25
                        if val > 0: # +0.25 surplus (e.g. bet -0.75, win by 1 -> net +0.25) -> Half Win
                            expected_value_prob += joint_prob * 0.5
                        else: # -0.25 deficit (e.g. bet -0.25, draw -> net -0.25) -> Half Loss
                            pass # 0 value
                            
        return expected_value_prob

    def calculate_1x2_probs(self, lambda_h, lambda_a, current_score=(0,0)):
        """
        Helper for UI to get Win/Draw/Loss probabilities
        """
        max_goals = 10
        cur_h, cur_a = current_score
        
        h_pmf = [poisson.pmf(i, lambda_h) for i in range(max_goals)]
        a_pmf = [poisson.pmf(i, lambda_a) for i in range(max_goals)]
        
        prob_home = 0.0
        prob_draw = 0.0
        prob_away = 0.0
        
        for h in range(max_goals):
            for a in range(max_goals):
                joint_prob = h_pmf[h] * a_pmf[a]
                final_h = cur_h + h
                final_a = cur_a + a
                
                if final_h > final_a:
                    prob_home += joint_prob
                elif final_h == final_a:
                    prob_draw += joint_prob
                else:
                    prob_away += joint_prob
                    
        return prob_home, prob_draw, prob_away



class AsianHandicapPricer:
    """
    3. äºšæ´²ç›˜å£è½¬æ¢å™¨ (Asian Handicap Pricer)
    é€»è¾‘ï¼šå°†æ¦‚ç‡è½¬åŒ–ä¸ºå…¬å¹³èµ”ç‡ã€‚
    """
    @staticmethod
    def calculate_fair_odds(lambda_home, lambda_away, current_score_diff, line):
        """
        è®¡ç®—ç‰¹å®šäºšç›˜ (line) ä¸‹çš„ä¸»èƒœå…¬å¹³èµ”ç‡ (Decimal Odds)ã€‚
        line: ç›˜å£ (é’ˆå¯¹ä¸»é˜Ÿ)ï¼Œå¦‚ -0.5, +0.5ã€‚
        current_score_diff: å½“å‰ä¸»é˜Ÿé¢†å…ˆçƒæ•° (ä¸» - å®¢)ã€‚
        """
        # èµ¢ç›˜æ¡ä»¶: (æœªæ¥ä¸» - æœªæ¥å®¢) + å½“å‰åˆ†å·® > -line
        # å³: å‡€èƒœçƒ > é˜ˆå€¼
        threshold = -1 * line - current_score_diff
        
        win_prob = 0.0
        push_prob = 0.0
        
        # æ¨¡æ‹Ÿå·ç§¯ (å¯ä»¥ç”¨ Skellam åˆ†å¸ƒä¼˜åŒ–ï¼Œè¿™é‡Œç”¨å¾ªç¯ç›´è§‚æ¼”ç¤º)
        for i in range(10):
            for j in range(10):
                p = poisson.pmf(i, lambda_home) * poisson.pmf(j, lambda_away)
                diff = i - j
                
                if diff > threshold + 0.1: # Win
                    win_prob += p
                elif abs(diff - threshold) < 0.1: # Draw/Push (èµ°æ°´)
                    push_prob += p
        
        # è®¡ç®—èµ”ç‡
        # å¯¹äºæ•´æ•°ç›˜ (å¦‚ -1.0)ï¼Œåˆ†æ¯é€šå¸¸æ’é™¤èµ°æ°´æ¦‚ç‡: P(Win) / (1 - P(Push))
        # å¯¹äºåŠçƒç›˜ (å¦‚ -0.5)ï¼Œæ— èµ°æ°´: P(Win)
        
        effective_win_prob = win_prob
        if push_prob > 0.01:
            effective_win_prob = win_prob / (1.0 - push_prob)
            
        if effective_win_prob < 0.01: return 99.0 # é˜²æ­¢æ— ç©·å¤§
        
        return round(1.0 / effective_win_prob, 2)


class OverUnderPricer:
    """
    3.5 å¤§å°çƒå®šä»·å™¨ (Over/Under Pricer)
    """
    @staticmethod
    def calculate_fair_odds(lambda_home, lambda_away, current_total_goals, line):
        """
        è®¡ç®—ç‰¹å®šå¤§å°ç›˜ (line) ä¸‹çš„å¤§çƒå…¬å¹³èµ”ç‡ (Over Odds).
        line: ç›˜å£å€¼ (å¦‚ 2.5).
        current_total_goals: å½“å‰æ¯”èµ›æ€»è¿›çƒæ•°.
        """
        # èµ¢ç›˜æ¡ä»¶: (æœªæ¥ä¸» + æœªæ¥å®¢) + å½“å‰æ€»çƒæ•° > line
        threshold = line - current_total_goals
        
        over_prob = 0.0
        push_prob = 0.0
        
        # ç®€å•çš„åŒé‡æ³Šæ¾å·ç§¯
        for i in range(10):
            for j in range(10):
                p = poisson.pmf(i, lambda_home) * poisson.pmf(j, lambda_away)
                total_future = i + j
                
                if total_future > threshold + 0.1: # Over Win
                    over_prob += p
                elif abs(total_future - threshold) < 0.1: # Push (èµ°æ°´)
                    push_prob += p
                    
        # è®¡ç®—èµ”ç‡
        effective_prob = over_prob
        if push_prob > 0.01:
            effective_prob = over_prob / (1.0 - push_prob)
            
        if effective_prob < 0.01: return 99.0
        
        return round(1.0 / effective_prob, 2)


class SignalGenerator:
    """
    4. äº¤æ˜“ä¿¡å·ç”Ÿæˆå™¨
    é€»è¾‘ï¼šå¯¹æ¯”æ¨¡å‹èµ”ç‡ä¸å¸‚åœºèµ”ç‡ï¼Œå¯»æ‰¾ä»·å€¼ã€‚
    """
    @staticmethod
    def analyze(fair_odds, market_odds, threshold=0.05):
        if market_odds == "-" or not market_odds: return None
        
        try:
            m_odd = float(market_odds)
            f_odd = float(fair_odds)
            
            # ä»·å€¼è®¡ç®—: (å¸‚åœºèµ”ç‡ / å…¬å¹³èµ”ç‡) - 1
            ev = (m_odd / f_odd) - 1.0
            
            if ev > threshold:
                return {
                    "signal": "VALUE BET",
                    "ev": round(ev * 100, 1), # ç™¾åˆ†æ¯”
                    "fair_odds": f_odd,
                    "market_odds": m_odd
                }
        except:
            pass
        return None
